{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414a8ce1",
   "metadata": {},
   "source": [
    "### Exercise: using PyTorch to train a small neural network to do MNIST classification. Goal: ~99% test accuracy using a 3-layer convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as tfms\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334f312",
   "metadata": {},
   "source": [
    "#### Get training data & show a few example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9523e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=tfms.ToTensor())\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=tfms.ToTensor())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "for i in range(3):\n",
    "    x, _ = mnist_trainset[i]\n",
    "    ax = axes[i]\n",
    "    ax.imshow(x.numpy()[0], cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc127b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0441c",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c46424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320) # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a02cce",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dedf970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fedcd7aa950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size = 128\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "# momentum = 0.5\n",
    "# log_interval = 10\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4edb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = SGD(model.parameters(), lr=0.07)#,momentum=momentum)\n",
    "\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9855794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "# test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(mnist_trainset): # enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(mnist_trainset),100. * batch_idx / len(mnist_trainset), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(mnist_dataset)))\n",
    "            #torch.save(network.state_dict(), '/results/model.pth')\n",
    "            #torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832bf59",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e545253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in enumerate(mnist_trainset):\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(testset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(testset),100. * correct / len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e52afe",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba6760d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (int, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-26b4aad1314a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-257e04027f7f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_trainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8d9f1f30ab6c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 453\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (int, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mint\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
